# COMPILER-DESIGN-BASICS

COMPANY:CODETECH IT SOLUTIONS

NAME:SAMPURNA NANDY

INTERN ID:CT04DL1283

DOMAIN:C LANGUAGE

DURATION:4 WEEKS

MENTOR:NEELA SANTOSH

*DESCRIBTION OF THIS CODE*:
This C program functions as a simple lexical analyzer that reads source code from a file named input.c and identifies keywords, identifiers, and operators within the code. It employs core features of the C programming language including standard input/output (stdio.h), dynamic memory allocation (stdlib.h), string manipulation (string.h), and character classification utilities (ctype.h). The program uses a predefined list of C keywords (such as int, float, if, else, return, etc.) and checks each word extracted from the file to determine whether it is a keyword or an identifier. It also recognizes single-character operators like +, -, *, /, =, <, and >. This lexical analysis is achieved by reading the file character by character, using buffers to form tokens, and classifying them based on syntactic rules. It makes use of functions like fgetc and ungetc for file reading and token control, while character checks are done using functions like isalpha, isalnum, and strcmp. The lexical analyzer outputs each recognized token type along with its content, making it a useful learning tool for understanding the first stage of a compiler: lexical analysis. This program can be created and run on various platforms such as Windows, Linux, or macOS using any text editor and a C compiler. Editors like Code::Blocks, Turbo C++, Visual Studio Code, or even basic editors like Notepad++ paired with a GCC compiler are suitable for writing and compiling this code. The purpose of this program is educational and practical, especially for students studying compiler design, language processing, or syntax analysis in computer science. It offers foundational insight into how a compiler breaks down source code into understandable tokens before parsing. Additionally, the program is extendable—more keywords, multi-character operators, comments, and literals could be added to improve its lexical recognition capabilities. In real-world applications, lexical analyzers are a core part of programming language interpreters, compilers, code editors (for syntax highlighting), and tools that analyze or transform source code. They are also vital in domains like static code analysis, code linters, and integrated development environments (IDEs). By understanding and building such tools, developers gain deeper insight into how code is interpreted and executed at a low level, thus becoming better programmers and system designers. This program, though simple, provides a strong conceptual foundation and demonstrates how raw source code can be programmatically analyzed, classified, and interpreted by a machine—a fundamental concept in computer science.

*OUTPUT*:
[Image](https://github.com/user-attachments/assets/b7ad5743-d6d3-4e00-8f04-7d2a13ae5281)






